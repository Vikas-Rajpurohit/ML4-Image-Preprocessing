{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "708bb874",
   "metadata": {},
   "source": [
    "## Optical Flow using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42a3cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b55a202",
   "metadata": {},
   "source": [
    "### 1. lucas Kanade \n",
    "- maxCorners: This parameter specifies the maximum number of corners to detect. It determines the total number of feature points that the algorithm will try to find in the image. Increasing this value allows more corners to be detected, potentially capturing more details, but it can also lead to increased computational complexity.\n",
    "</br>\n",
    "</br>\n",
    "- qualityLevel: This parameter defines the minimum accepted quality level for a corner to be considered. It represents a value between 0 and 1, indicating the minimum \"strength\" or \"cornerness\" of a corner. Corners with a higher \"strength\" value (closer to 1) are more likely to be selected as feature points. Adjusting this parameter affects the sensitivity of the corner detection algorithm. A higher value results in fewer selected corners but potentially higher quality.\n",
    "</br>\n",
    "</br>\n",
    "- minDistance: This parameter sets the minimum Euclidean distance between detected corners. It ensures that the selected corners are spread out across the image and are not too close to each other. A larger minDistance value enforces a greater spatial distribution of feature points, preventing them from being too densely packed.\n",
    "</br>\n",
    "</br>\n",
    "- blockSize: This parameter defines the size of the neighborhood considered for corner detection. It specifies the size of the Sobel operator aperture used to calculate the gradient at each pixel. A larger blockSize captures corners with larger-scale variations in intensity, while a smaller value focuses on smaller-scale variations. Adjusting this parameter can impact the size and scale of the detected corners.\n",
    "</br>\n",
    "</br>\n",
    "- winSize: This parameter defines the size of the search window for each pyramid level. The window size determines the spatial extent within which the algorithm searches for corresponding points in the next frame. A larger window size can capture larger motion but may result in decreased accuracy. Conversely, a smaller window size can provide more precise estimates but may struggle with larger displacements or occlusions.\n",
    "</br>\n",
    "</br>\n",
    "- maxLevel: This parameter specifies the maximum pyramid level for the iterative algorithm. The Lucas-Kanade algorithm operates on image pyramids, where each level represents a different scale of the image. By limiting the maximum pyramid level, you control the level of detail considered during the optical flow estimation. Higher pyramid levels capture finer details but increase computational complexity.\n",
    "</br>\n",
    "</br>\n",
    "- criteria: This parameter defines the termination criteria for the iterative algorithm. It is specified as a tuple (type, maxCount, epsilon), where: \n",
    " - type specifies the type of termination criteria. Here, we use a combination of cv2.TERM_CRITERIA_EPS and cv2.TERM_CRITERIA_COUNT, which indicate that the algorithm terminates based on a maximum number of iterations (maxCount) or a specified change in the estimated points (epsilon).\n",
    " - maxCount determines the maximum number of iterations before the algorithm terminates.\n",
    " - epsilon sets the required accuracy for the estimated points. A smaller value indicates higher precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d00ed179",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('Videos\\Video2.mp4')\n",
    "\n",
    "# params for ShiTomasi Corner Detection\n",
    "feature_params = dict( maxCorners = 2500,\n",
    "                     qualityLevel = 0.7,\n",
    "                     minDistance = 5,\n",
    "                     blockSize = 2)\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize = (40,40),\n",
    "                maxLevel = 5,\n",
    "                criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 20, 0.03))\n",
    "\n",
    "# create random colors\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "# Take first frame and find corners in it\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate Optical Flow\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray,\n",
    "                                              gray, p0,\n",
    "                                              None, **lk_params)\n",
    "\n",
    "        # Select good points\n",
    "        good_new = p1[st==1]\n",
    "        good_old = p0[st==1]\n",
    "\n",
    "        # Draw the Tracks\n",
    "        # Iterating through all points from detected points\n",
    "        for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "            a,b = new.ravel()\n",
    "            c,d = old.ravel()\n",
    "\n",
    "            mask = cv2.line(mask, (int(a),int(b)), (int(c),int(d)), color[i].tolist(), 2)\n",
    "            frame = cv2.circle(frame, (int(a),int(b)), 5, color[i].tolist(), -1)\n",
    "\n",
    "        img = cv2.add(frame,mask)\n",
    "        cv2.imshow('Optical Flow',img)\n",
    "        \n",
    "        old_gray = gray.copy()\n",
    "        p0 = good_new.reshape(-1,1,2)\n",
    "    \n",
    "    if cv2.waitKey(15) & 0xFF == 27:\n",
    "        break\n",
    "        \n",
    "    \n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3e68e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cfd1ac",
   "metadata": {},
   "source": [
    "### 2. Gunner Farneback's Algorithm\n",
    "\n",
    "- prvs: The previous frame (gray-scale) used as input for optical flow calculation.\n",
    "</br>\n",
    "</br>\n",
    "- new: The current frame (gray-scale) used as input for optical flow calculation.\n",
    "</br>\n",
    "</br>\n",
    "- None: Placeholder for the output flow image (not used in this case).\n",
    "</br>\n",
    "</br>\n",
    "- 0.5: The pyramid scale factor. It controls the image scale in the pyramid. A smaller value leads to more levels in the pyramid and finer details captured.\n",
    "</br>\n",
    "</br>\n",
    "- 3: The number of pyramid levels. It represents the number of times the image is downsampled in the pyramid. More levels allow capturing larger motion.\n",
    "</br>\n",
    "</br>\n",
    "- 15: The window size. It specifies the size of the neighborhood used for calculating the optical flow. A larger window size captures more global motion but may lead to less accurate results for small motions.\n",
    "</br>\n",
    "</br>\n",
    "- 3: The number of iterations of the algorithm at each pyramid level. More iterations can improve accuracy but also increase computational cost.\n",
    "</br>\n",
    "</br>\n",
    "- 5: The size of the pixel neighborhood used to find polynomial expansion for each pixel. A larger value captures more local motion but may introduce more noise.\n",
    "</br>\n",
    "</br>\n",
    "- 1.2: The standard deviation of the Gaussian used for smoothing derivatives used as a basis for the polynomial expansion. A larger value increases the influence of distant pixels and can capture larger motions.\n",
    "</br>\n",
    "</br>\n",
    "- 0: Additional flags. Setting it to 0 means no additional options are enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71b0438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('Videos\\Video2.mp4')\n",
    "\n",
    "# create random colors\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "# Take first frame and find corners in it\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "# Assigning 255 to Saturation Value in hsv Image\n",
    "hsv[...,1] =  255\n",
    "\n",
    "while True:\n",
    "    ret, frame2 = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        new = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate Optical Flow\n",
    "        # Parameters (prev, next, flow, pyr_scale, levels, winsize, iterations, poly_n, poly_sigma, flags)\n",
    "        flow = cv2.calcOpticalFlowFarneback(prvs, new, None, \n",
    "                                            0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "        mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "        hsv[...,0] = ang*180 / np.pi/2\n",
    "        hsv[...,2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "        img = cv2.add(frame2,rgb)\n",
    "        \n",
    "        cv2.imshow('Optical Flow',img)\n",
    "        \n",
    "        prvs = new\n",
    "    \n",
    "    if cv2.waitKey(25) & 0xFF == 27:\n",
    "        break   \n",
    "    \n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d493b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed1269c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d023cf8",
   "metadata": {},
   "source": [
    "### Keypoint :\n",
    "-  If you need dense flow estimation and want to capture detailed motion information, the Farneback method can be a good choice. If you are interested in sparse flow estimation and precise feature tracking, the Lucas-Kanade method with feature point tracking may be more suitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe308d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
